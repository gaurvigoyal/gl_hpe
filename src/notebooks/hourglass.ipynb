{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gianscarpe/dev/event-camera/src\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".npy|.mat\n"
     ]
    }
   ],
   "source": [
    "from experimenting.dataset.factory import (\n",
    "        AutoEncoderConstructor,\n",
    "        ClassificationConstructor,\n",
    "        HeatmapConstructor,\n",
    "        Joints3DConstructor,\n",
    "        JointsConstructor\n",
    ")\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "data_dir = '/data/gscarpellini/dhp19/time_count_dataset/movements_per_frame'\n",
    "labels_dir = '/data/gscarpellini/dhp19/time_count_dataset/labels'\n",
    "joints_dir = '/data/gscarpellini/dhp19/time_count_dataset/labels_joints'\n",
    "hparams = DictConfig({\n",
    "        'dataset': {\n",
    "                'data_dir': data_dir,\n",
    "                'joints_dir': joints_dir,\n",
    "                'save_split': False,\n",
    "                'labels_dir': labels_dir,\n",
    "                'hm_dir': labels_dir,\n",
    "                'test_subjects': [1, 2, 3, 4, 5],\n",
    "                'split_at': 0.8,\n",
    "                'cams': [3],\n",
    "                'params_class': 'DHP19Core'\n",
    "        },\n",
    "        'augmentation_train': {\n",
    "                'info': {},\n",
    "                'apply': {'aug1': {'cls': 'albumentations.CenterCrop', 'params':\n",
    "                                   {'height': 256, 'width': 256, 'p': 1}},\n",
    "                          'aug2': {'cls':'albumentations.pytorch.ToTensor'}}\n",
    "        },\n",
    "        'augmentation_test': {\n",
    "                'info': {},\n",
    "                'apply': {}\n",
    "        }\n",
    "})\n",
    "data_constructor = JointsConstructor(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train, val , test = data_constructor.get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<experimenting.dataset.dataset.HeatmapDataset at 0x7fd457610f90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y, m = train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DHPJointsDataset' from 'experimenting.dataset' (/home/gianscarpe/dev/event-camera/src/experimenting/dataset/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-78d064d299a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mexperimenting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDHPJointsDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexperimenting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_dataset_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0malbumentations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCenterCrop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DHPJointsDataset' from 'experimenting.dataset' (/home/gianscarpe/dev/event-camera/src/experimenting/dataset/__init__.py)"
     ]
    }
   ],
   "source": [
    "from experimenting.dataset import get_dataloader, DHPJointsDataset\n",
    "from experimenting.dataset.params_utils import get_dataset_params\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from albumentations import Compose, CenterCrop\n",
    "from albumentations.pytorch import ToTensor\n",
    "import torch\n",
    "from importlib import reload  \n",
    "from experimenting.models import metrics\n",
    "from experimenting.models import losses\n",
    "from kornia import geometry\n",
    "from omegaconf import DictConfig\n",
    "import kornia\n",
    "from experimenting.utils import get_file_paths\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def display(img):          \n",
    "        fig, ax = plt.subplots(ncols=img.shape[0], nrows=1,                              \n",
    "                               figsize=(20,20))                                                                                   \n",
    "        for i in range(img.shape[0]):                                                                \n",
    "            ax[i].imshow(img[i])                                                  \n",
    "            ax[i].axis('off')\n",
    "        plt.show()\n",
    "def plot_2d(dvs_frame, sample_gt, sample_pred):\n",
    "    \" To plot image and 2D ground truth and prediction \"\n",
    "    plt.figure()\n",
    "    plt.imshow(dvs_frame, cmap='gray')\n",
    "    plt.plot(sample_gt[:,1], sample_gt[:,0], '.', c='red', label='gt')\n",
    "    plt.plot(sample_pred[:,1], sample_pred[:,0], '.', c='blue', label='pred')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Augmentation\n",
    "aug = Compose([ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".npy|.mat\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/data/dhp19/time_count_dataset/movements_per_frame'\n",
    "labels_dir = \"/data/dhp19/time_count_dataset/labels_full_joints/\"\n",
    "test_subjects = [1, 2, 3, 4, 5]\n",
    "cams = [2, 3]\n",
    "max_h = 959.81\n",
    "max_w = 867.40\n",
    "max_d = 2238.23\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "hparams = DictConfig({'data_dir': data_dir, 'save_split':False, 'max_d':max_d,\n",
    "                      'max_h':max_h, 'max_w': max_w, 'labels_dir' :\n",
    "                      labels_dir, 'test_subjects':test_subjects, 'split_at':0.8, 'cams': cams})\n",
    "params = get_dataset_params(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "indexes = np.concatenate([params['train_indexes'], params['val_indexes']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "d = DHPJointsDataset(file_paths = params['file_paths'], labels_dir = labels_dir,\n",
    "                     indexes=params['test_indexes'], max_w= max_w, max_h= max_h,\n",
    "                     transform=aug)\n",
    "loader = get_dataloader(d, batch_size, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "batch = next(iter(loader))\n",
    "x, y, m = batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pose3d_utils.skeleton_normaliser import SkeletonNormaliser\n",
    "from pose3d_utils.camera import CameraIntrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "s = SkeletonNormaliser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "yt = np.concatenate([y['xyz'], np.ones((1, 13)) ])\n",
    "y = M.dot(yt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#skeelton\n",
    "skeleton = np.concatenate([y, np.ones((1, 13)) ]).swapaxes(0, 1)\n",
    "#depth\n",
    "z_ref = 2853\n",
    "#h\n",
    "height = 256\n",
    "width = 256\n",
    "#intr\n",
    "camera = CameraIntrinsics(torch.tensor(bnp.concatenate([K, np.zeros((3, 1)) ],\n",
    "                                                      axis=1)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "n = s.normalise_skeleton(torch.tensor(skeleton), z_ref, camera, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.7225e+01, -6.8450e+02,  2.8540e+03,  1.0000e+00],\n",
       "        [ 1.8078e+02, -4.3547e+02,  2.9805e+03,  1.0000e+00],\n",
       "        [-7.3541e+01, -5.8244e+02,  3.1666e+03,  1.0000e+00],\n",
       "        [ 3.8864e+02, -3.4739e+02,  3.1975e+03,  1.0000e+00],\n",
       "        [-3.2393e+01, -5.0766e+02,  3.4474e+03,  1.0000e+00],\n",
       "        [ 1.3886e+02, -1.0007e+02,  3.2464e+03,  1.0000e+00],\n",
       "        [-4.7059e+01, -1.8356e+02,  3.3878e+03,  1.0000e+00],\n",
       "        [ 4.9648e+02, -7.4138e+01,  3.2529e+03,  1.0000e+00],\n",
       "        [-1.3820e+02, -3.5746e+02,  3.6709e+03,  1.0000e+00],\n",
       "        [ 6.1916e+01,  3.1874e+02,  3.4282e+03,  1.0000e+00],\n",
       "        [-9.3804e+01,  2.7155e+02,  3.5520e+03,  1.0000e+00],\n",
       "        [ 4.1933e+01,  7.0362e+02,  3.5826e+03,  1.0000e+00],\n",
       "        [-1.3423e+02,  6.3978e+02,  3.7041e+03,  1.0000e+00]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.denormalise_skeleton(n, z_ref, camera, height, width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval hourglass model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mexp_Adam_0.0003_no_aug_05-28-14-56\u001b[0m/  \u001b[01;34mexp_Adam_0.0003_no_aug_06-12-11-38\u001b[0m/\n",
      "\u001b[01;34mexp_Adam_0.0003_no_aug_05-28-15-17\u001b[0m/  \u001b[01;34mexp_SGD_0.001_no_aug_05-28-14-13\u001b[0m/\n",
      "\u001b[01;34mexp_Adam_0.0003_no_aug_05-28-15-19\u001b[0m/  \u001b[01;34mexp_SGD_0.001_no_aug_05-28-14-15\u001b[0m/\n",
      "\u001b[01;34mexp_Adam_0.0003_no_aug_05-28-15-21\u001b[0m/  \u001b[01;34mexp_SGD_0.001_no_aug_05-28-14-24\u001b[0m/\n",
      "\u001b[01;34mexp_Adam_0.0003_no_aug_05-28-15-40\u001b[0m/  \u001b[01;34mexp_SGD_0.001_no_aug_05-28-15-48\u001b[0m/\n",
      "\u001b[01;34mexp_Adam_0.0003_no_aug_05-28-15-44\u001b[0m/  \u001b[01;34mexp_SGD_0.01_no_aug_05-22-11-05\u001b[0m/\n",
      "\u001b[01;34mexp_Adam_0.0003_no_aug_06-01-08-49\u001b[0m/  \u001b[01;34mexp_SGD_0.01_no_aug_05-26-09-51\u001b[0m/\n",
      "\u001b[01;34mexp_Adam_0.0003_no_aug_06-03-14-53\u001b[0m/  \u001b[01;34mexp_SGD_0.01_no_aug_05-28-11-28\u001b[0m/\n",
      "\u001b[01;34mexp_Adam_0.0003_no_aug_06-11-14-22\u001b[0m/  \u001b[01;34mexp_SGD_0.1_no_aug_05-28-15-56\u001b[0m/\n",
      "\u001b[01;34mexp_Adam_0.0003_no_aug_06-11-14-59\u001b[0m/  \u001b[01;34mexp_SGD_0.1_no_aug_05-29-10-56\u001b[0m/\n",
      "\u001b[01;34mexp_Adam_0.0003_no_aug_06-12-10-00\u001b[0m/  \u001b[01;34mexp_SGD_0.1_no_aug_05-30-10-37\u001b[0m/\n",
      "\u001b[01;34mexp_Adam_0.0003_no_aug_06-12-10-08\u001b[0m/  \u001b[01;34mwith_errors\u001b[0m/\n",
      "\u001b[01;34mexp_Adam_0.0003_no_aug_06-12-10-10\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls /home/gianscarpe/dev/exps/timecount_pose/exps_HourglassModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import experimenting.models as models\n",
    "import os\n",
    "import experimenting.models.metrics as metrics\n",
    "import experimenting.models.losses as losses\n",
    "from experimenting.utils import get_joints_from_heatmap, average_loss\n",
    "\n",
    "#exp_name = 'exps_HourglassModel/exp_Adam_0.0003_no_aug_05-25-12-57'\n",
    "exp_name = 'exps_HourglassModel/exp_Adam_0.0003_no_aug_06-12-10-10'\n",
    "checkpoint_dir = f'/home/gianscarpe/dev/exps/timecount_pose/{exp_name}/checkpoints'\n",
    "checkpoints = sorted(os.listdir(checkpoint_dir))\n",
    "checkpoint_path = os.path.join(checkpoint_dir, checkpoints[0])\n",
    "model = models.HourglassEstimator.load_from_checkpoint(checkpoint_path)\n",
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gianscarpe/dev/exps/timecount_pose/exps_HourglassModel/exp_Adam_0.0003_no_aug_06-12-10-10/checkpoints/epoch=00-val_loss=1.63.ckpt'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mpjpe = metrics.MPJPE(reduction=average_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    preds = model(x.cpu())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NpzFile' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-7174173f9246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp_joints\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdenormalize_pixel_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial_expectation2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgt_joints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdenormalize_pixel_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/event-camera/lib/python3.7/site-packages/kornia/geometry/conversions.py\u001b[0m in \u001b[0;36mdenormalize_pixel_coordinates\u001b[0;34m(pixel_coordinates, height, width, eps)\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdenormalized\u001b[0m \u001b[0mpixel\u001b[0m \u001b[0mcoordinates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \"\"\"\n\u001b[0;32m--> 667\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mpixel_coordinates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m         raise ValueError(\"Input pixel_coordinates must be of shape (*, 2). \"\n\u001b[1;32m    669\u001b[0m                          \"Got {}\".format(pixel_coordinates.shape))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NpzFile' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "p_joints =  geometry.denormalize_pixel_coordinates(geometry.spatial_expectation2d(preds), d.max_h, d.max_w) \n",
    "gt_joints = geometry.denormalize_pixel_coordinates(y, d.max_h, d.max_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(279.9998, dtype=torch.float64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpjpe(p_joints, gt_joints, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(preds[10].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-446-609181d1e0bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mplot_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_joints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_joints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(batch_size):\n",
    "    display(preds[i].numpy())\n",
    "    plot_2d(x[i].squeeze(), p_joints[i], gt_joints[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "name": "hourglass.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
