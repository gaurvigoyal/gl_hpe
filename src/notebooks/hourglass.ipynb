{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gianscarpe/dev/event-camera/src\n"
     ]
    }
   ],
   "source": [
    "%cd event-camera/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from experimenting.dataset import get_dataloader, DHPJointsDataset\n",
    "from experimenting.dataset.indexes import get_dataset_params\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from albumentations import Compose, CenterCrop\n",
    "from albumentations.pytorch import ToTensor\n",
    "import torch\n",
    "from importlib import reload  \n",
    "from experimenting.models import metrics\n",
    "from experimenting.models import losses\n",
    "from kornia import geometry\n",
    "from omegaconf import DictConfig\n",
    "import kornia\n",
    "from experimenting.utils import get_file_paths\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display(img):          \n",
    "        fig, ax = plt.subplots(ncols=img.shape[0], nrows=1,                              \n",
    "                               figsize=(20,20))                                                                                   \n",
    "        for i in range(img.shape[0]):                                                                \n",
    "            ax[i].imshow(img[i])                                                  \n",
    "            ax[i].axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_2d(dvs_frame, sample_gt, sample_pred):\n",
    "    \" To plot image and 2D ground truth and prediction \"\n",
    "    plt.figure()\n",
    "    plt.imshow(dvs_frame, cmap='gray')\n",
    "    plt.plot(sample_gt[:,1], sample_gt[:,0], '.', c='red', label='gt')\n",
    "    plt.plot(sample_pred[:,1], sample_pred[:,0], '.', c='blue', label='pred')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Augmentation\n",
    "aug = Compose([ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".npy|.mat\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/data/dhp19/time_count_dataset/movements_per_frame'\n",
    "labels_dir = \"/data/dhp19/time_count_dataset/labels_joints/\"\n",
    "test_subjects = [1, 2, 3, 4, 5]\n",
    "cams = [2, 3]\n",
    "max_w = 300\n",
    "max_h = 342\n",
    "batch_size = 16\n",
    "\n",
    "hparams = DictConfig({'data_dir': data_dir, 'save_split':False, 'labels_dir' : labels_dir, 'test_subjects':test_subjects, 'cams': cams})\n",
    "params = get_dataset_params(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = DHPJointsDataset(file_paths = params['file_paths'], labels_dir = labels_dir, indexes=params['test_indexes'], max_w= max_w, max_h= max_h, transform=aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loader = get_dataloader(d, batch_size, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch = next(iter(loader))\n",
    "x, y, m = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 37.0000, 148.0000],\n",
       "        [ 73.0000, 134.0000],\n",
       "        [ 65.0000, 156.0000],\n",
       "        [102.0000, 129.0000],\n",
       "        [ 95.0000, 161.0000],\n",
       "        [114.0000, 150.0000],\n",
       "        [107.0000, 164.0000],\n",
       "        [132.0000, 124.0000],\n",
       "        [108.0000, 187.0000],\n",
       "        [156.0000, 170.0000],\n",
       "        [152.0000, 163.0000],\n",
       "        [195.0000, 161.0000],\n",
       "        [190.0000, 168.0000]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geometry.denormalize_pixel_coordinates(y[0], max_h, max_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mexp_Adam_0.0003_no_aug_05-28-09-50\u001b[0m/  \u001b[01;34mexp_SGD_0.001_no_aug_05-28-14-24\u001b[0m/\r\n",
      "\u001b[01;34mexp_Adam_0.0003_no_aug_05-28-14-56\u001b[0m/  \u001b[01;34mexp_SGD_0.001_no_aug_05-28-15-48\u001b[0m/\r\n",
      "\u001b[01;34mexp_Adam_0.0003_no_aug_05-28-15-17\u001b[0m/  \u001b[01;34mexp_SGD_0.01_no_aug_05-22-11-05\u001b[0m/\r\n",
      "\u001b[01;34mexp_Adam_0.0003_no_aug_05-28-15-19\u001b[0m/  \u001b[01;34mexp_SGD_0.01_no_aug_05-26-09-51\u001b[0m/\r\n",
      "\u001b[01;34mexp_Adam_0.0003_no_aug_05-28-15-21\u001b[0m/  \u001b[01;34mexp_SGD_0.01_no_aug_05-28-11-28\u001b[0m/\r\n",
      "\u001b[01;34mexp_Adam_0.0003_no_aug_05-28-15-40\u001b[0m/  \u001b[01;34mexp_SGD_0.1_no_aug_05-28-15-56\u001b[0m/\r\n",
      "\u001b[01;34mexp_Adam_0.0003_no_aug_05-28-15-44\u001b[0m/  \u001b[01;34mexp_SGD_0.1_no_aug_05-29-10-56\u001b[0m/\r\n",
      "\u001b[01;34mexp_SGD_0.001_no_aug_05-28-14-13\u001b[0m/    \u001b[01;34mexp_SGD_0.1_no_aug_05-30-10-37\u001b[0m/\r\n",
      "\u001b[01;34mexp_SGD_0.001_no_aug_05-28-14-15\u001b[0m/    \u001b[01;34mwith_errors\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls /home/gianscarpe/dev/exps/timecount_pose/exps_HourglassModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/gianscarpe/dev/exps/timecount_pose/exps_HourglassModel/exp_SGD_0.01_no_aug_05-25-12-57/checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fddebe7a25cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mexp_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'exps_HourglassModel/exp_SGD_0.01_no_aug_05-25-12-57'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'/home/gianscarpe/dev/exps/timecount_pose/{exp_name}/checkpoints'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcheckpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHourglassEstimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/gianscarpe/dev/exps/timecount_pose/exps_HourglassModel/exp_SGD_0.01_no_aug_05-25-12-57/checkpoints'"
     ]
    }
   ],
   "source": [
    "import experimenting.models as models\n",
    "import os\n",
    "import experimenting.models.metrics as metrics\n",
    "import experimenting.models.losses as losses\n",
    "from experimenting.utils import get_joints_from_heatmap, average_loss\n",
    "\n",
    "exp_name = 'exps_HourglassModel/exp_Adam_0.0003_no_aug_05-25-12-57'\n",
    "checkpoint_dir = f'/home/gianscarpe/dev/exps/timecount_pose/{exp_name}/checkpoints'\n",
    "checkpoints = sorted(os.listdir(checkpoint_dir))\n",
    "checkpoint_path = os.path.join(checkpoint_dir, checkpoints[0])\n",
    "model = models.HourglassEstimator.load_from_checkpoint(checkpoint_path)\n",
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gianscarpe/dev/exps/timecount_pose/exps_HourglassModel/exp_Adam_0.0003_no_aug_05-25-12-57/checkpoints/epoch=16-val_loss=0.03.ckpt'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mpjpe = metrics.MPJPE(reduction=average_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    preds = model(x.cpu())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_joints =  geometry.denormalize_pixel_coordinates(geometry.spatial_expectation2d(preds), d.max_h, d.max_w) \n",
    "gt_joints = geometry.denormalize_pixel_coordinates(y, max_h, max_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.0457)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpjpe(p_joints, gt_joints, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-609181d1e0bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mplot_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_joints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_joints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(batch_size):\n",
    "    display(preds[i].numpy())\n",
    "    plot_2d(x[i].squeeze(), p_joints[i], gt_joints[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/home/gianscarpe/anaconda3/envs/event-camera/bin/python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "name": "hourglass.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
